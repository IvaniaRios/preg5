{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNuaVzSB/pvEtO7hWln8U9c"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","\n","# Montar Google Drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZHsAHw23izcU","executionInfo":{"status":"ok","timestamp":1728213424231,"user_tz":240,"elapsed":47692,"user":{"displayName":"Alakir Meneses peres","userId":"09853550789562380167"}},"outputId":"807e3e17-964d-4c5c-f5c9-94c6b5ca05cb"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7Qjk7QRwimNY","executionInfo":{"status":"ok","timestamp":1728215397639,"user_tz":240,"elapsed":359,"user":{"displayName":"Alakir Meneses peres","userId":"09853550789562380167"}},"outputId":"0eb8f1e2-2fad-41c4-8a88-d22c855391e0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Coeficientes (Pesos): [0.37454012 0.95071431 0.73199394 0.59865848 0.15601864 0.15599452\n"," 0.05808361 0.86617615]\n","Costo Total: 2.9306\n","Costo L1: 0.0389\n","Costo L2: 0.0274\n"]}],"source":["import numpy as np\n","\n","# Función para leer el archivo ARFF\n","def leer_arff(ruta_archivo):\n","    with open(ruta_archivo, 'r') as archivo:\n","        lineas = archivo.readlines()\n","\n","    datos = []\n","    start_data = False\n","\n","    for linea in lineas:\n","        if linea.startswith('@data'):\n","            start_data = True\n","            continue\n","        if start_data:\n","            fila = [float(valor) if valor != '?' else None for valor in linea.strip().split(',')]\n","            datos.append(fila)\n","\n","    return np.array(datos, dtype=float)\n","\n","# Función para imputar datos faltantes\n","def imputar_datos(datos):\n","    # Reemplazamos los NaN (que son los valores faltantes) por la media de cada columna\n","    for i in range(datos.shape[1]):\n","        media = np.nanmean(datos[:, i])  # Calculamos la media ignorando NaN\n","        datos[:, i] = np.where(np.isnan(datos[:, i]), media, datos[:, i])\n","\n","    return datos\n","\n","# Función para normalizar los datos\n","def normalizar_datos(datos):\n","    return (datos - np.mean(datos, axis=0)) / np.std(datos, axis=0)\n","\n","# Función de costo con regularización L1 y L2\n","def costo_con_penalizacion(y_true, y_pred, w, lambda_l1=0.01, lambda_l2=0.01):\n","    error = np.mean((y_true - y_pred) ** 2)\n","    penalizacion_l1 = lambda_l1 * np.sum(np.abs(w))\n","    penalizacion_l2 = lambda_l2 * np.sum(w ** 2)\n","\n","    # Retornamos el costo total y los costos individuales\n","    return error + penalizacion_l1 + penalizacion_l2, penalizacion_l1, penalizacion_l2\n","\n","# Ejemplo de uso\n","ruta_archivo = '/content/drive/My Drive/354/primer_parcial/water_quality.arff'\n","datos = leer_arff(ruta_archivo)\n","datos_imputados = imputar_datos(datos)\n","\n","# Separando las características y la variable objetivo\n","X = datos_imputados[:, :-1]  # Todas las columnas excepto la última\n","y = datos_imputados[:, -1]    # Última columna como variable objetivo\n","\n","# Normalizando los datos\n","X_normalizado = normalizar_datos(X)\n","\n","# Inicializando pesos (ejemplo aleatorio)\n","np.random.seed(42)  # Para reproducibilidad\n","w = np.random.rand(X_normalizado.shape[1])\n","\n","# Haciendo una predicción simple (puedes ajustar esto a tu modelo)\n","y_pred = np.dot(X_normalizado, w)\n","\n","# Calculando el costo\n","costo_total, costo_l1, costo_l2 = costo_con_penalizacion(y, y_pred, w)\n","\n","# Mostrando resultados\n","print(\"Coeficientes (Pesos):\", w)\n","print(f\"Costo Total: {costo_total:.4f}\")\n","print(f\"Costo L1: {costo_l1:.4f}\")\n","print(f\"Costo L2: {costo_l2:.4f}\")\n"]},{"cell_type":"markdown","source":["# Análisis e Iterpretacion\n","\n","# Coeficientes (Pesos):\n","\n","Los valores obtenidos para los coeficientes indican la influencia de cada variable en la predicción de la variable objetivo. Un coeficiente más alto sugiere un mayor impacto.\n","\n","# Costo Total: 2.9306:\n","\n","Este es el costo total del modelo, que incluye errores de predicción y penalizaciones. Un costo total más bajo indica un mejor ajuste del modelo a los datos.\n","\n","# Costo L1: 0.0389:\n","\n","Representa la penalización L1, que ayuda a reducir el sobreajuste y puede hacer que algunos coeficientes sean cero, simplificando el modelo.\n","\n","# Costo L2: 0.0274:\n","\n","Refleja la penalización L2, que suaviza los coeficientes sin eliminarlos por completo, ayudando a mantener todas las características en el modelo."],"metadata":{"id":"CjJ4XCPysngx"}}]}